
\section*{Partie 3 – Super Learner}

Nous avons implémenté un \textbf{Super Learner}, une méthode ensembliste qui combine les prédictions de plusieurs modèles pour améliorer la performance globale. Dans notre cas, nous avons utilisé trois modèles de base :
\begin{itemize}
    \item \textbf{Logistic Regression}
    \item \textbf{Random Forest}
    \item \textbf{SVC (avec StandardScaler)}
\end{itemize}

Ces modèles ont été entraînés sur les représentations \textbf{TF-IDF} des SMS.

Le modèle \textbf{méta} utilisé est une régression logistique, entraînée à partir des prédictions des trois modèles de base sur des validations croisées (StratifiedKFold à 5 plis).

\subsection*{Résultats du Super Learner}
\begin{itemize}
    \item \textbf{Accuracy} : 0.9832
    \item \textbf{F1 Score} : 0.9344
\end{itemize}

Ces résultats dépassent légèrement les meilleurs scores obtenus avec un seul modèle, démontrant l’intérêt d’une combinaison pondérée.

\subsection*{Poids attribués par le méta-modèle}
\begin{center}
\begin{tabular}{|l|c|}
\hline
\textbf{Modèle} & \textbf{Poids appris} \\
\hline
Logistic Regression & 4.72 \\
Random Forest & 6.23 \\
SVC (linéaire) & 2.99 \\
\hline
\end{tabular}
\end{center}

Cela signifie que le Super Learner fait davantage confiance aux prédictions du Random Forest et de la régression logistique, tout en conservant une contribution significative du SVC.

\subsection*{Commentaires sur les graphiques}

Le graphique comparatif des \textbf{F1-scores} montre clairement que le Super Learner surpasse tous les modèles individuels :

\begin{itemize}
    \item Logistic Regression : 0.9182
    \item Random Forest : 0.8938
    \item SVC linéaire : 0.9100
    \item Super Learner : \textbf{0.9344}
\end{itemize}

On constate donc que la combinaison pondérée permet d'exploiter les forces complémentaires des modèles de base, ce qui se traduit par une meilleure généralisation.
